{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae918a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89970374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9930c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model = \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d374ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining schema for structured output\n",
    "\n",
    "class SentimentSchema(BaseModel):\n",
    "    sentiment: Literal['positive', 'negative'] = Field(description=\"sentiment of review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7113e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structured schema for diagnosis of negative response\n",
    "\n",
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\" \"Performance\",\"Bug\",\"Support\",\"Other\"] = Field(description=\"The category of issue mentioned in the review\")\n",
    "    tone: Literal[\"angry\",\"frustrated\",\"dissapointed\",\"calm\"] = Field(description=\"The emotional tone expressed by the user\")\n",
    "    urgency: Literal[\"low\",\"medium\",\"high\"] = Field(description=\"How urgent and critical teh issue appears to be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13db06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "structuredModel = model.with_structured_output(SentimentSchema)\n",
    "structuredModel2 = model.with_structured_output(DiagnosisSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f906a50a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mwhat is the sentiment of the following review: The software is too bad\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mstructuredModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m.sentiment\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\vs code\\langgraph\\myenv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3088\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3086\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3087\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3088\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3089\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3090\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\vs code\\langgraph\\myenv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5489\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5482\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5483\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5484\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5487\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5488\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5490\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5491\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5492\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5493\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\vs code\\langgraph\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:379\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m     **kwargs: Any,\n\u001b[32m    373\u001b[39m ) -> AIMessage:\n\u001b[32m    374\u001b[39m     config = ensure_config(config)\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    376\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    377\u001b[39m         cast(\n\u001b[32m    378\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    389\u001b[39m         ).message,\n\u001b[32m    390\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\vs code\\langgraph\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1088\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1079\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1081\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m     **kwargs: Any,\n\u001b[32m   1086\u001b[39m ) -> LLMResult:\n\u001b[32m   1087\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\vs code\\langgraph\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:903\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    902\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m         )\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    911\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\vs code\\langgraph\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1192\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1190\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1196\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\vs code\\langgraph\\myenv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1299\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1298\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1299\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1302\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1303\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1304\u001b[39m ):\n\u001b[32m   1305\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\vs code\\langgraph\\myenv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1267\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1264\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1266\u001b[39m     raw_response = (\n\u001b[32m-> \u001b[39m\u001b[32m1267\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1268\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\n\u001b[32m   1269\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1270\u001b[39m     )\n\u001b[32m   1271\u001b[39m     response = raw_response.parse()\n\u001b[32m   1272\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\vs code\\langgraph\\myenv\\Lib\\site-packages\\openai\\_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\vs code\\langgraph\\myenv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:183\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    178\u001b[39m         response_format=response_format,\n\u001b[32m    179\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    180\u001b[39m         input_tools=chat_completion_tools,\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\vs code\\langgraph\\myenv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\vs code\\langgraph\\myenv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "prompt = f'what is the sentiment of the following review: The software is too bad'\n",
    "structuredModel.invoke(prompt).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba88832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define state\n",
    "class ReviewState(TypedDict):\n",
    "    review: str\n",
    "    sentiment: Literal[\"positive\",\"negative\"]\n",
    "    diagnosis: dict\n",
    "    response: str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108cf7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state:ReviewState):\n",
    "    prompt = f'for the following review find out the sentiment \\n{state[\"review\"]}'\n",
    "    sentiment= structuredModel.invoke(prompt).sentiment\n",
    "    return {'sentiment',sentiment}\n",
    "\n",
    "\n",
    "def check_sentiment(state:ReviewState) -> Literal[\"positive_response\",\"run_diagnosis\"]:\n",
    "    if state['sentiment'] == 'positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'\n",
    "\n",
    "def positive_response(state:ReviewState):\n",
    "    prompt = f'write a warm thankyou message in response to this  review \\n {state['review']} \\n Also kindly ask the user to leave feedback on our website'\n",
    "    response = model.invoke(prompt).content\n",
    "    return {'response': response}\n",
    "\n",
    "def run_diagnosis(state:ReviewState):\n",
    "    prompt = f'Diagnose this negative review \\n {state[\"review\"]} \\n Return issue_type, tone and urgency'\n",
    "    response = structuredModel2.invoke(prompt)\n",
    "    return {'diagnosis':response.model.dump()}\n",
    "\n",
    "\n",
    "def negative_response(state:ReviewState):\n",
    "    diagnosis = state['diagnosis']\n",
    "    prompt = f\"\"\"You are a support Assistant.\n",
    "      The user had a diagnosis '{diagnosis[\"issue_type\"]}' issue, sounded '{diagnosis['tone']}' \n",
    "      and marked urgency as '{diagnosis['urgency']}'\n",
    "      Write an empathetic, helpful resolution message\"\"\"\n",
    "    \n",
    "    response = model.invoke(prompt).content\n",
    "    return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb13833e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001B73B31C920>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define graph\n",
    "\n",
    "graph = StateGraph(ReviewState)\n",
    "\n",
    "# add nodes\n",
    "graph.add_node('find_sentiment',find_sentiment)\n",
    "graph.add_node('positive_response',positive_response)\n",
    "graph.add_node('run_diagnosis',run_diagnosis)\n",
    "graph.add_node('negative_response',negative_response)\n",
    "\n",
    "\n",
    "# add edges\n",
    "graph.add_edge(START,'find_sentiment')\n",
    "graph.add_conditional_edges('find_sentiment',check_sentiment)\n",
    "graph.add_edge('positive_response',END)\n",
    "graph.add_edge('run_diagnosis',negative_response)\n",
    "graph.add_edge('negative_response',END)\n",
    "\n",
    "workflow =  graph.compile()\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52accd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    'review': \"I've been using this app for about a month now, and I must say, the user interface is incredibly clean and intuitive. Everything is exactly where you'd expect it to be. It's rare to find something that just works without needing a tutorial Great job to the design team!\"\n",
    "}\n",
    "\n",
    "workflow.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
